{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e255bd9-079d-4c6b-b071-2e73f836d243",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d4fc0-c549-45bf-bf46-ed187ddb6089",
   "metadata": {},
   "source": [
    "### Directories and text loading\n",
    "Initially we will set the main directories and some variables regarding the characteristics of our texts.\n",
    "We set the maximum sequence length to 25, the maximun number of words in our vocabulary to 12000 and we will use 300-dimensional embeddings. Finally we load our texts from a csv. The text file is the train file of the Quora Kaggle challenge containing around 808000 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01882ef2-1ff4-45b5-ae4b-96d93e537953",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of rows to load (set to None to load all rows)\n",
    "num_rows = 1000  # Replace with the desired number of rows to load, or set to None for all rows\n",
    "\n",
    "# Load the data\n",
    "if num_rows is None:\n",
    "    data = pd.read_csv('test.csv')\n",
    "else:\n",
    "    data = pd.read_csv('test.csv', nrows=num_rows)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22bba65-3516-42af-9121-4167fe201557",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "To preprocess the text we will use the tokenizer and the text_to_sequences function from Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c36c857-7703-450d-953e-272ec9dba9f8",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>how does the surface pro himself 4 compare wit...</td>\n",
       "      <td>why did microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>should i have a hair transplant at age 24 how ...</td>\n",
       "      <td>how much cost does hair transplant require</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>what but is the best way to send money from ch...</td>\n",
       "      <td>what you send money to china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>which food not emulsifiers</td>\n",
       "      <td>what foods fibre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>how aberystwyth start reading</td>\n",
       "      <td>how their can i start reading</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  how does the surface pro himself 4 compare wit...   \n",
       "1        1  should i have a hair transplant at age 24 how ...   \n",
       "2        2  what but is the best way to send money from ch...   \n",
       "3        3                         which food not emulsifiers   \n",
       "4        4                      how aberystwyth start reading   \n",
       "\n",
       "                                           question2  \n",
       "0  why did microsoft choose core m3 and not core ...  \n",
       "1         how much cost does hair transplant require  \n",
       "2                       what you send money to china  \n",
       "3                                   what foods fibre  \n",
       "4                      how their can i start reading  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Lowercase the text\n",
    "        text = text.lower()\n",
    "        # Remove punctuation\n",
    "        text = re.sub(f'[{string.punctuation}]', '', text)\n",
    "    else:\n",
    "        text = ''\n",
    "    return text\n",
    "\n",
    "data['question1'] = data['question1'].apply(preprocess_text)\n",
    "data['question2'] = data['question2'].apply(preprocess_text)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c1c8a7f-c22d-4868-a532-5a806fda50a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea2d635-bb32-42a0-b1a9-62b607ee7c8a",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load pre-trained model tokenizer (vocabulary)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set the model in evaluation mode to deactivate the DropOut modules\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def tokenize_and_embed(text):\n",
    "    # Add the special tokens.\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "\n",
    "    # Split the sentence into tokens.\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "    # Map the token strings to their vocabulary indices.\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "\n",
    "    # Get the embeddings\n",
    "    embeddings = outputs.last_hidden_state\n",
    "\n",
    "    # Calculate the mean embeddings\n",
    "    mean_embeddings = torch.mean(embeddings, dim=1).cpu().numpy()\n",
    "\n",
    "    return mean_embeddings\n",
    "\n",
    "data['question1'] = data['question1'].apply(tokenize_and_embed)\n",
    "data['question2'] = data['question2'].apply(tokenize_and_embed)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a52da8f-ffb4-44c3-9e45-799487989821",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Pad the sequences to a fixed length\n",
    "def pad_sequence(sequence):\n",
    "    if len(sequence) > 100:\n",
    "        return sequence[:100]\n",
    "    else:\n",
    "        return np.pad(sequence, (0, 100 - len(sequence)), 'constant')\n",
    "\n",
    "data['question1'] = data['question1'].apply(pad_sequence)\n",
    "data['question2'] = data['question2'].apply(pad_sequence)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb70c84-6a27-4c80-a018-a73b9ed4d97d",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(100, 50)\n",
    "        self.fc21 = nn.Linear(50, 20)\n",
    "        self.fc22 = nn.Linear(50, 20)\n",
    "        self.fc3 = nn.Linear(20, 50)\n",
    "        self.fc4 = nn.Linear(50, 100)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 100))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b27bd3-3a2d-42ba-9abe-85cadaf11468",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 100), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4615057c-5640-40f4-873f-551e005dbcda",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data1, data2) in enumerate(zip(data['question1'], data['question2'])):\n",
    "        data1 = torch.from_numpy(data1)\n",
    "        data2 = torch.from_numpy(data2)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data1)\n",
    "        loss = loss_function(recon_batch, data2, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data1), len(data['question1']),\n",
    "                100. * batch_idx / len(data['question1']),\n",
    "                loss.item() / len(data1)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(data['question1'])))\n",
    "\n",
    "for epoch in range(1, 10 + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020bf3f-dc07-468b-8477-7fb95ba75a08",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    }
   },
   "outputs": [],
   "source": [
    "def generate_text(epoch):\n",
    "    model.eval()\n",
    "    sample = torch.randn(64, 20)\n",
    "    sample = model.decode(sample)\n",
    "    print('====> Generated text after epoch {}: {}'.format(epoch, sample))\n",
    "\n",
    "for epoch in range(1, 10 + 1):\n",
    "    generate_text(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "noteable": {
   "last_delta_id": "73c4ed83-5be9-452e-9a29-53503bdcbbef",
   "last_transaction_id": "446f9eee-17b3-4123-b58b-4301bfa0b6a1"
  },
  "noteable-chatgpt": {
   "create_notebook": {
    "openai_conversation_id": "b2c6ef96-6967-5cef-872b-98d4c190f96e",
    "openai_ephemeral_user_id": "4eca9769-3ab9-5591-bb64-729453b68e61",
    "openai_subdivision1_iso_code": "AU-NSW"
   }
  },
  "nteract": {
   "version": "noteable@2.9.0"
  },
  "selected_hardware_size": "small"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
