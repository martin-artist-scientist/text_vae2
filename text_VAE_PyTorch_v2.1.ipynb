{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e255bd9-079d-4c6b-b071-2e73f836d243",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f2d4fc0-c549-45bf-bf46-ed187ddb6089",
   "metadata": {},
   "source": [
    "### Directories and text loading\n",
    "Initially we will set the main directories and some variables regarding the characteristics of our texts.\n",
    "We set the maximum sequence length to 25, the maximun number of words in our vocabulary to 12000 and we will use 300-dimensional embeddings. Finally we load our texts from a csv. The text file is the train file of the Quora Kaggle challenge containing around 808000 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "01882ef2-1ff4-45b5-ae4b-96d93e537953",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How does the Surface Pro himself 4 compare wit...</td>\n",
       "      <td>Why did Microsoft choose core m3 and not core ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Should I have a hair transplant at age 24? How...</td>\n",
       "      <td>How much cost does hair transplant require?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>What but is the best way to send money from Ch...</td>\n",
       "      <td>What you send money to China?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Which food not emulsifiers?</td>\n",
       "      <td>What foods fibre?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How \"aberystwyth\" start reading?</td>\n",
       "      <td>How their can I start reading?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  How does the Surface Pro himself 4 compare wit...   \n",
       "1        1  Should I have a hair transplant at age 24? How...   \n",
       "2        2  What but is the best way to send money from Ch...   \n",
       "3        3                        Which food not emulsifiers?   \n",
       "4        4                   How \"aberystwyth\" start reading?   \n",
       "\n",
       "                                           question2  \n",
       "0  Why did Microsoft choose core m3 and not core ...  \n",
       "1        How much cost does hair transplant require?  \n",
       "2                      What you send money to China?  \n",
       "3                                  What foods fibre?  \n",
       "4                     How their can I start reading?  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the number of rows to load (set to None to load all rows)\n",
    "num_rows = 1000  # Replace with the desired number of rows to load, or set to None for all rows\n",
    "\n",
    "# Load the data\n",
    "if num_rows is None:\n",
    "    data = pd.read_csv('test.csv')\n",
    "else:\n",
    "    data = pd.read_csv('test.csv', nrows=num_rows)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22bba65-3516-42af-9121-4167fe201557",
   "metadata": {},
   "source": [
    "### Text Preprocessing\n",
    "To preprocess the text we will use the tokenizer and the text_to_sequences function from Keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c36c857-7703-450d-953e-272ec9dba9f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T05:29:49.033083+00:00",
     "start_time": "2023-07-01T05:29:48.499030+00:00"
    },
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "      <td>[input_ids, token_type_ids, attention_mask]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                    question1  \\\n",
       "0        0  [input_ids, token_type_ids, attention_mask]   \n",
       "1        1  [input_ids, token_type_ids, attention_mask]   \n",
       "2        2  [input_ids, token_type_ids, attention_mask]   \n",
       "3        3  [input_ids, token_type_ids, attention_mask]   \n",
       "4        4  [input_ids, token_type_ids, attention_mask]   \n",
       "\n",
       "                                     question2  \n",
       "0  [input_ids, token_type_ids, attention_mask]  \n",
       "1  [input_ids, token_type_ids, attention_mask]  \n",
       "2  [input_ids, token_type_ids, attention_mask]  \n",
       "3  [input_ids, token_type_ids, attention_mask]  \n",
       "4  [input_ids, token_type_ids, attention_mask]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Lowercase the text\n",
    "        text = text.lower()\n",
    "        # Remove punctuation\n",
    "        text = re.sub(f'[{string.punctuation}]', '', text)\n",
    "    else:\n",
    "        text = ''\n",
    "    return text\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "data['question1'] = data['question1'].apply(lambda x: tokenizer.encode_plus(preprocess_text(x), truncation=True, max_length=128, padding='max_length'))\n",
    "data['question2'] = data['question2'].apply(lambda x: tokenizer.encode_plus(preprocess_text(x), truncation=True, max_length=128, padding='max_length'))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c1c8a7f-c22d-4868-a532-5a806fda50a1",
   "metadata": {
    "noteable": {},
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cea2d635-bb32-42a0-b1a9-62b607ee7c8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T05:30:21.180834+00:00",
     "start_time": "2023-07-01T05:30:20.995338+00:00"
    },
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.008112554, 0.06914526, 0.82839537, -0.0284...</td>\n",
       "      <td>[[0.09557229, -0.17299807, 0.7814211, 0.026063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0508408, 0.039784312, 0.78486174, -0.10946...</td>\n",
       "      <td>[[0.0725258, 0.051574327, 0.8558014, 0.0115733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.06462372, -0.08754915, 0.770723, -0.044196...</td>\n",
       "      <td>[[0.108965725, 0.08205171, 0.884027, 0.0054321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[0.094933055, 0.02714562, 0.90626955, 0.04580...</td>\n",
       "      <td>[[0.066027835, 0.174642, 0.9134673, 0.03110914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[0.0927197, -0.00010966638, 0.8752658, 0.0102...</td>\n",
       "      <td>[[0.041761775, 0.090365164, 0.8690901, 0.01229...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  [[0.008112554, 0.06914526, 0.82839537, -0.0284...   \n",
       "1        1  [[0.0508408, 0.039784312, 0.78486174, -0.10946...   \n",
       "2        2  [[0.06462372, -0.08754915, 0.770723, -0.044196...   \n",
       "3        3  [[0.094933055, 0.02714562, 0.90626955, 0.04580...   \n",
       "4        4  [[0.0927197, -0.00010966638, 0.8752658, 0.0102...   \n",
       "\n",
       "                                           question2  \n",
       "0  [[0.09557229, -0.17299807, 0.7814211, 0.026063...  \n",
       "1  [[0.0725258, 0.051574327, 0.8558014, 0.0115733...  \n",
       "2  [[0.108965725, 0.08205171, 0.884027, 0.0054321...  \n",
       "3  [[0.066027835, 0.174642, 0.9134673, 0.03110914...  \n",
       "4  [[0.041761775, 0.090365164, 0.8690901, 0.01229...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set the model in evaluation mode to deactivate the DropOut modules\n",
    "model.eval()\n",
    "\n",
    "# If you have a GPU, put everything on cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def embed_text(token_ids):\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([token_ids]).to(device)\n",
    "\n",
    "    # Predict hidden states features for each layer\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "\n",
    "    # Get the embeddings\n",
    "    embeddings = outputs.last_hidden_state\n",
    "\n",
    "    # Calculate the mean embeddings\n",
    "    mean_embeddings = torch.mean(embeddings, dim=1).cpu().numpy()\n",
    "\n",
    "    return mean_embeddings\n",
    "\n",
    "data['question1'] = data['question1'].apply(lambda x: embed_text(x['input_ids']))\n",
    "data['question2'] = data['question2'].apply(lambda x: embed_text(x['input_ids']))\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a52da8f-ffb4-44c3-9e45-799487989821",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_id</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[[0.008112554, 0.06914526, 0.82839537, -0.0284...</td>\n",
       "      <td>[[0.09557229, -0.17299807, 0.7814211, 0.026063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0508408, 0.039784312, 0.78486174, -0.10946...</td>\n",
       "      <td>[[0.0725258, 0.051574327, 0.8558014, 0.0115733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[[0.06462372, -0.08754915, 0.770723, -0.044196...</td>\n",
       "      <td>[[0.108965725, 0.08205171, 0.884027, 0.0054321...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[[0.094933055, 0.02714562, 0.90626955, 0.04580...</td>\n",
       "      <td>[[0.066027835, 0.174642, 0.9134673, 0.03110914...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[[0.0927197, -0.00010966638, 0.8752658, 0.0102...</td>\n",
       "      <td>[[0.041761775, 0.090365164, 0.8690901, 0.01229...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_id                                          question1  \\\n",
       "0        0  [[0.008112554, 0.06914526, 0.82839537, -0.0284...   \n",
       "1        1  [[0.0508408, 0.039784312, 0.78486174, -0.10946...   \n",
       "2        2  [[0.06462372, -0.08754915, 0.770723, -0.044196...   \n",
       "3        3  [[0.094933055, 0.02714562, 0.90626955, 0.04580...   \n",
       "4        4  [[0.0927197, -0.00010966638, 0.8752658, 0.0102...   \n",
       "\n",
       "                                           question2  \n",
       "0  [[0.09557229, -0.17299807, 0.7814211, 0.026063...  \n",
       "1  [[0.0725258, 0.051574327, 0.8558014, 0.0115733...  \n",
       "2  [[0.108965725, 0.08205171, 0.884027, 0.0054321...  \n",
       "3  [[0.066027835, 0.174642, 0.9134673, 0.03110914...  \n",
       "4  [[0.041761775, 0.090365164, 0.8690901, 0.01229...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the sequences to a fixed length\n",
    "def pad_sequence(sequence):\n",
    "    if len(sequence) > 768:\n",
    "        return sequence[:768]\n",
    "    else:\n",
    "        return np.pad(sequence, (0, 768 - len(sequence)), 'constant')\n",
    "\n",
    "data['question1'] = data['question1'].apply(pad_sequence)\n",
    "data['question2'] = data['question2'].apply(pad_sequence)\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb70c84-6a27-4c80-a018-a73b9ed4d97d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T05:30:49.937836+00:00",
     "start_time": "2023-07-01T05:30:49.745850+00:00"
    },
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 768)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 768))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32b27bd3-3a2d-42ba-9abe-85cadaf11468",
   "metadata": {
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = VAE()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 768), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4615057c-5640-40f4-873f-551e005dbcda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T05:31:22.629012+00:00",
     "start_time": "2023-07-01T05:31:22.427936+00:00"
    },
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/1000 (0%)]\tLoss: 1067.521240\n",
      "Train Epoch: 1 [76800/1000 (10%)]\tLoss: 9.734870\n",
      "Train Epoch: 1 [153600/1000 (20%)]\tLoss: 5.671806\n",
      "Train Epoch: 1 [230400/1000 (30%)]\tLoss: 2.635507\n",
      "Train Epoch: 1 [307200/1000 (40%)]\tLoss: 0.012108\n",
      "Train Epoch: 1 [384000/1000 (50%)]\tLoss: -2.331642\n",
      "Train Epoch: 1 [460800/1000 (60%)]\tLoss: -3.840911\n",
      "Train Epoch: 1 [537600/1000 (70%)]\tLoss: -5.009164\n",
      "Train Epoch: 1 [614400/1000 (80%)]\tLoss: -5.608404\n",
      "Train Epoch: 1 [691200/1000 (90%)]\tLoss: -5.267151\n",
      "====> Epoch: 1 Average loss: 9286.9299\n",
      "Train Epoch: 2 [0/1000 (0%)]\tLoss: -5.938011\n",
      "Train Epoch: 2 [76800/1000 (10%)]\tLoss: -6.108155\n",
      "Train Epoch: 2 [153600/1000 (20%)]\tLoss: -6.382324\n",
      "Train Epoch: 2 [230400/1000 (30%)]\tLoss: -6.879962\n",
      "Train Epoch: 2 [307200/1000 (40%)]\tLoss: -5.862769\n",
      "Train Epoch: 2 [384000/1000 (50%)]\tLoss: -6.112744\n",
      "Train Epoch: 2 [460800/1000 (60%)]\tLoss: -7.241020\n",
      "Train Epoch: 2 [537600/1000 (70%)]\tLoss: -6.195230\n",
      "Train Epoch: 2 [614400/1000 (80%)]\tLoss: -6.862540\n",
      "Train Epoch: 2 [691200/1000 (90%)]\tLoss: -5.494143\n",
      "====> Epoch: 2 Average loss: -4856.0141\n",
      "Train Epoch: 3 [0/1000 (0%)]\tLoss: -6.505143\n",
      "Train Epoch: 3 [76800/1000 (10%)]\tLoss: -6.626286\n",
      "Train Epoch: 3 [153600/1000 (20%)]\tLoss: -6.768552\n",
      "Train Epoch: 3 [230400/1000 (30%)]\tLoss: -6.943448\n",
      "Train Epoch: 3 [307200/1000 (40%)]\tLoss: -6.781509\n",
      "Train Epoch: 3 [384000/1000 (50%)]\tLoss: -6.113843\n",
      "Train Epoch: 3 [460800/1000 (60%)]\tLoss: -8.075214\n",
      "Train Epoch: 3 [537600/1000 (70%)]\tLoss: -7.509813\n",
      "Train Epoch: 3 [614400/1000 (80%)]\tLoss: -7.109634\n",
      "Train Epoch: 3 [691200/1000 (90%)]\tLoss: -5.893064\n",
      "====> Epoch: 3 Average loss: -5177.7998\n",
      "Train Epoch: 4 [0/1000 (0%)]\tLoss: -7.361141\n",
      "Train Epoch: 4 [76800/1000 (10%)]\tLoss: -6.354160\n",
      "Train Epoch: 4 [153600/1000 (20%)]\tLoss: -7.839722\n",
      "Train Epoch: 4 [230400/1000 (30%)]\tLoss: -7.614370\n",
      "Train Epoch: 4 [307200/1000 (40%)]\tLoss: -7.087294\n",
      "Train Epoch: 4 [384000/1000 (50%)]\tLoss: -6.868144\n",
      "Train Epoch: 4 [460800/1000 (60%)]\tLoss: -7.693480\n",
      "Train Epoch: 4 [537600/1000 (70%)]\tLoss: -6.848686\n",
      "Train Epoch: 4 [614400/1000 (80%)]\tLoss: -7.008667\n",
      "Train Epoch: 4 [691200/1000 (90%)]\tLoss: -6.887087\n",
      "====> Epoch: 4 Average loss: -5336.1405\n",
      "Train Epoch: 5 [0/1000 (0%)]\tLoss: -7.025284\n",
      "Train Epoch: 5 [76800/1000 (10%)]\tLoss: -7.385013\n",
      "Train Epoch: 5 [153600/1000 (20%)]\tLoss: -7.265155\n",
      "Train Epoch: 5 [230400/1000 (30%)]\tLoss: -7.036344\n",
      "Train Epoch: 5 [307200/1000 (40%)]\tLoss: -7.959716\n",
      "Train Epoch: 5 [384000/1000 (50%)]\tLoss: -7.384153\n",
      "Train Epoch: 5 [460800/1000 (60%)]\tLoss: -6.793272\n",
      "Train Epoch: 5 [537600/1000 (70%)]\tLoss: -7.382287\n",
      "Train Epoch: 5 [614400/1000 (80%)]\tLoss: -7.274160\n",
      "Train Epoch: 5 [691200/1000 (90%)]\tLoss: -5.932280\n",
      "====> Epoch: 5 Average loss: -5455.9805\n",
      "Train Epoch: 6 [0/1000 (0%)]\tLoss: -7.171963\n",
      "Train Epoch: 6 [76800/1000 (10%)]\tLoss: -7.707043\n",
      "Train Epoch: 6 [153600/1000 (20%)]\tLoss: -8.251436\n",
      "Train Epoch: 6 [230400/1000 (30%)]\tLoss: -7.864027\n",
      "Train Epoch: 6 [307200/1000 (40%)]\tLoss: -8.351470\n",
      "Train Epoch: 6 [384000/1000 (50%)]\tLoss: -7.728870\n",
      "Train Epoch: 6 [460800/1000 (60%)]\tLoss: -7.277584\n",
      "Train Epoch: 6 [537600/1000 (70%)]\tLoss: -7.401753\n",
      "Train Epoch: 6 [614400/1000 (80%)]\tLoss: -6.853784\n",
      "Train Epoch: 6 [691200/1000 (90%)]\tLoss: -7.163687\n",
      "====> Epoch: 6 Average loss: -5657.7103\n",
      "Train Epoch: 7 [0/1000 (0%)]\tLoss: -6.688293\n",
      "Train Epoch: 7 [76800/1000 (10%)]\tLoss: -7.700468\n",
      "Train Epoch: 7 [153600/1000 (20%)]\tLoss: -8.026709\n",
      "Train Epoch: 7 [230400/1000 (30%)]\tLoss: -7.929783\n",
      "Train Epoch: 7 [307200/1000 (40%)]\tLoss: -7.681058\n",
      "Train Epoch: 7 [384000/1000 (50%)]\tLoss: -7.512873\n",
      "Train Epoch: 7 [460800/1000 (60%)]\tLoss: -7.324187\n",
      "Train Epoch: 7 [537600/1000 (70%)]\tLoss: -7.979721\n",
      "Train Epoch: 7 [614400/1000 (80%)]\tLoss: -8.187798\n",
      "Train Epoch: 7 [691200/1000 (90%)]\tLoss: -7.132645\n",
      "====> Epoch: 7 Average loss: -5738.8227\n",
      "Train Epoch: 8 [0/1000 (0%)]\tLoss: -7.604959\n",
      "Train Epoch: 8 [76800/1000 (10%)]\tLoss: -8.011721\n",
      "Train Epoch: 8 [153600/1000 (20%)]\tLoss: -6.995925\n",
      "Train Epoch: 8 [230400/1000 (30%)]\tLoss: -8.820871\n",
      "Train Epoch: 8 [307200/1000 (40%)]\tLoss: -7.603459\n",
      "Train Epoch: 8 [384000/1000 (50%)]\tLoss: -6.774906\n",
      "Train Epoch: 8 [460800/1000 (60%)]\tLoss: -8.174629\n",
      "Train Epoch: 8 [537600/1000 (70%)]\tLoss: -7.359936\n",
      "Train Epoch: 8 [614400/1000 (80%)]\tLoss: -8.623167\n",
      "Train Epoch: 8 [691200/1000 (90%)]\tLoss: -6.129615\n",
      "====> Epoch: 8 Average loss: -5788.5171\n",
      "Train Epoch: 9 [0/1000 (0%)]\tLoss: -7.955489\n",
      "Train Epoch: 9 [76800/1000 (10%)]\tLoss: -8.956345\n",
      "Train Epoch: 9 [153600/1000 (20%)]\tLoss: -7.463690\n",
      "Train Epoch: 9 [230400/1000 (30%)]\tLoss: -9.348852\n",
      "Train Epoch: 9 [307200/1000 (40%)]\tLoss: -9.063011\n",
      "Train Epoch: 9 [384000/1000 (50%)]\tLoss: -7.482498\n",
      "Train Epoch: 9 [460800/1000 (60%)]\tLoss: -7.457662\n",
      "Train Epoch: 9 [537600/1000 (70%)]\tLoss: -8.918986\n",
      "Train Epoch: 9 [614400/1000 (80%)]\tLoss: -7.793015\n",
      "Train Epoch: 9 [691200/1000 (90%)]\tLoss: -6.964925\n",
      "====> Epoch: 9 Average loss: -5920.8930\n",
      "Train Epoch: 10 [0/1000 (0%)]\tLoss: -7.664307\n",
      "Train Epoch: 10 [76800/1000 (10%)]\tLoss: -7.572382\n",
      "Train Epoch: 10 [153600/1000 (20%)]\tLoss: -7.827784\n",
      "Train Epoch: 10 [230400/1000 (30%)]\tLoss: -8.203275\n",
      "Train Epoch: 10 [307200/1000 (40%)]\tLoss: -8.475632\n",
      "Train Epoch: 10 [384000/1000 (50%)]\tLoss: -8.181701\n",
      "Train Epoch: 10 [460800/1000 (60%)]\tLoss: -8.017596\n",
      "Train Epoch: 10 [537600/1000 (70%)]\tLoss: -8.108934\n",
      "Train Epoch: 10 [614400/1000 (80%)]\tLoss: -8.516137\n",
      "Train Epoch: 10 [691200/1000 (90%)]\tLoss: -6.890264\n",
      "====> Epoch: 10 Average loss: -6006.6479\n"
     ]
    }
   ],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data1, data2) in enumerate(zip(data['question1'], data['question2'])):\n",
    "        data1 = torch.from_numpy(data1).to(device)\n",
    "        data2 = torch.from_numpy(data2).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        recon_batch, mu, logvar = model(data1)\n",
    "        loss = loss_function(recon_batch, data2, mu, logvar)\n",
    "        loss.backward()\n",
    "        train_loss += loss.item()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data1), len(data['question1']),\n",
    "                100. * batch_idx / len(data['question1']),\n",
    "                loss.item() / len(data1)))\n",
    "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "          epoch, train_loss / len(data['question1'])))\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(1, 10 + 1):\n",
    "    train(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8020bf3f-dc07-468b-8477-7fb95ba75a08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T05:31:38.889469+00:00",
     "start_time": "2023-07-01T05:31:38.697931+00:00"
    },
    "noteable": {
     "cell_type": "code"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Generated text after epoch 1: tensor([[1.0365e-09, 1.4379e-10, 1.7433e-10,  ..., 1.7085e-10, 4.2704e-10,\n",
      "         4.4689e-11],\n",
      "        [4.0141e-08, 2.9771e-08, 8.6892e-09,  ..., 3.7323e-10, 5.0252e-08,\n",
      "         1.8946e-10],\n",
      "        [1.2563e-08, 2.2677e-08, 7.5842e-09,  ..., 5.3965e-09, 2.8370e-08,\n",
      "         6.7865e-09],\n",
      "        ...,\n",
      "        [4.0368e-08, 8.0555e-08, 1.3332e-08,  ..., 5.7228e-08, 4.7695e-08,\n",
      "         4.0183e-08],\n",
      "        [2.1063e-10, 2.9002e-10, 2.1242e-11,  ..., 2.4457e-09, 2.1469e-10,\n",
      "         2.7679e-09],\n",
      "        [4.6671e-13, 1.3650e-12, 1.1403e-14,  ..., 5.0697e-11, 1.2009e-13,\n",
      "         2.8793e-11]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 2: tensor([[2.2246e-12, 1.5727e-12, 7.0746e-14,  ..., 1.3778e-10, 8.9174e-13,\n",
      "         3.4440e-11],\n",
      "        [1.3399e-09, 3.8761e-09, 1.8175e-10,  ..., 1.3242e-07, 1.4153e-09,\n",
      "         8.2754e-08],\n",
      "        [1.5745e-10, 2.9044e-10, 9.9887e-12,  ..., 6.6498e-10, 3.0875e-10,\n",
      "         1.0973e-09],\n",
      "        ...,\n",
      "        [2.3357e-06, 4.5247e-07, 3.1068e-06,  ..., 2.6281e-11, 1.7231e-06,\n",
      "         2.6962e-11],\n",
      "        [3.4759e-07, 7.7081e-08, 8.8815e-07,  ..., 1.0941e-13, 1.5187e-07,\n",
      "         8.5143e-14],\n",
      "        [8.1757e-12, 9.7431e-12, 6.1884e-13,  ..., 9.8232e-10, 1.5384e-11,\n",
      "         8.0527e-10]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 3: tensor([[5.8823e-09, 2.7902e-09, 3.6347e-09,  ..., 1.0460e-11, 7.7948e-09,\n",
      "         5.6023e-12],\n",
      "        [1.5076e-11, 5.5890e-11, 6.5695e-13,  ..., 8.6048e-10, 1.0527e-11,\n",
      "         5.8053e-10],\n",
      "        [9.8471e-09, 5.2710e-09, 5.6146e-10,  ..., 3.1579e-08, 2.4280e-09,\n",
      "         3.4675e-08],\n",
      "        ...,\n",
      "        [1.1828e-07, 1.7960e-07, 4.8830e-08,  ..., 5.0960e-07, 1.1032e-07,\n",
      "         8.3469e-07],\n",
      "        [1.4459e-06, 8.2098e-07, 8.5516e-07,  ..., 8.0673e-09, 1.4779e-06,\n",
      "         3.3064e-09],\n",
      "        [1.2784e-06, 6.8818e-07, 1.0037e-06,  ..., 4.1445e-08, 9.7037e-07,\n",
      "         4.8790e-08]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 4: tensor([[4.1941e-10, 5.6385e-10, 8.2136e-11,  ..., 6.4976e-10, 3.4202e-10,\n",
      "         5.5481e-10],\n",
      "        [3.9016e-09, 4.0009e-09, 2.5256e-09,  ..., 1.2769e-10, 3.0837e-09,\n",
      "         2.4810e-10],\n",
      "        [4.2525e-10, 1.0210e-09, 5.3853e-11,  ..., 1.3242e-09, 5.9976e-10,\n",
      "         3.0213e-09],\n",
      "        ...,\n",
      "        [8.6558e-10, 2.9404e-09, 1.3402e-10,  ..., 2.7299e-08, 6.5987e-10,\n",
      "         4.0215e-08],\n",
      "        [1.7702e-08, 7.9204e-09, 7.1107e-09,  ..., 7.4343e-12, 1.2982e-08,\n",
      "         4.4226e-12],\n",
      "        [1.0296e-10, 9.9101e-11, 3.7864e-12,  ..., 6.0410e-09, 6.2047e-11,\n",
      "         9.5870e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 5: tensor([[1.3423e-11, 2.8373e-11, 7.2840e-13,  ..., 1.3780e-09, 4.8893e-12,\n",
      "         1.8895e-09],\n",
      "        [1.3341e-07, 1.9674e-07, 3.5722e-08,  ..., 5.1359e-07, 6.5167e-08,\n",
      "         5.9895e-07],\n",
      "        [1.0987e-09, 2.8792e-09, 4.3246e-10,  ..., 4.6118e-09, 8.1861e-10,\n",
      "         3.2046e-09],\n",
      "        ...,\n",
      "        [4.5847e-10, 1.0418e-09, 8.5193e-11,  ..., 1.4572e-09, 2.9382e-10,\n",
      "         6.9384e-10],\n",
      "        [4.4482e-09, 1.7547e-09, 1.3716e-09,  ..., 1.5195e-12, 2.4629e-09,\n",
      "         8.0601e-13],\n",
      "        [1.8944e-10, 3.0354e-10, 1.0134e-11,  ..., 1.8431e-08, 7.5367e-11,\n",
      "         7.2692e-09]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 6: tensor([[1.8707e-09, 4.0566e-09, 2.1378e-10,  ..., 2.6331e-08, 2.9843e-09,\n",
      "         5.1367e-08],\n",
      "        [8.9130e-09, 1.4899e-08, 1.0364e-09,  ..., 7.0835e-08, 3.8862e-09,\n",
      "         6.0694e-08],\n",
      "        [2.8221e-09, 7.5188e-09, 5.1095e-10,  ..., 9.9935e-09, 1.2875e-09,\n",
      "         1.2116e-08],\n",
      "        ...,\n",
      "        [3.4746e-08, 8.3351e-08, 3.5010e-09,  ..., 8.7584e-07, 2.1773e-08,\n",
      "         6.3115e-07],\n",
      "        [6.0041e-11, 1.4449e-10, 8.6806e-12,  ..., 2.1874e-09, 5.5343e-11,\n",
      "         4.5796e-09],\n",
      "        [2.3039e-11, 2.5223e-11, 5.6928e-13,  ..., 2.2303e-09, 7.2316e-12,\n",
      "         7.3604e-10]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 7: tensor([[8.2496e-08, 1.3668e-07, 2.6469e-08,  ..., 4.3139e-07, 5.4191e-08,\n",
      "         4.0168e-07],\n",
      "        [6.3579e-12, 3.4202e-11, 9.5121e-13,  ..., 1.3650e-09, 1.2578e-11,\n",
      "         1.1242e-09],\n",
      "        [2.8999e-09, 3.7191e-09, 1.9765e-10,  ..., 6.9832e-08, 1.6082e-09,\n",
      "         7.6698e-08],\n",
      "        ...,\n",
      "        [2.4562e-08, 2.8832e-08, 2.6953e-08,  ..., 6.3239e-12, 1.0575e-08,\n",
      "         1.2323e-11],\n",
      "        [3.4398e-10, 5.8160e-10, 2.5498e-11,  ..., 1.1538e-08, 3.0983e-10,\n",
      "         1.6156e-08],\n",
      "        [3.1426e-07, 3.8247e-08, 3.6658e-07,  ..., 1.4170e-12, 1.5299e-07,\n",
      "         1.1608e-12]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 8: tensor([[3.8456e-07, 2.0572e-07, 2.0279e-07,  ..., 5.1234e-08, 2.9784e-07,\n",
      "         2.6693e-08],\n",
      "        [6.7775e-10, 1.0127e-09, 1.2707e-10,  ..., 1.3931e-09, 9.7593e-10,\n",
      "         2.0638e-09],\n",
      "        [1.7904e-07, 1.5334e-07, 2.3662e-07,  ..., 4.1292e-11, 1.0417e-07,\n",
      "         6.6845e-11],\n",
      "        ...,\n",
      "        [5.1696e-11, 4.3831e-11, 3.2295e-12,  ..., 2.7241e-10, 1.8376e-11,\n",
      "         2.5093e-10],\n",
      "        [1.9496e-06, 1.1052e-06, 8.1191e-07,  ..., 1.5650e-08, 1.2262e-06,\n",
      "         1.9324e-08],\n",
      "        [8.3601e-08, 8.5809e-08, 5.1214e-08,  ..., 1.7582e-07, 5.8613e-08,\n",
      "         1.5348e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 9: tensor([[3.0456e-09, 6.6795e-09, 4.4115e-10,  ..., 2.4955e-08, 2.6267e-09,\n",
      "         2.8272e-08],\n",
      "        [6.7438e-09, 2.3222e-09, 2.4471e-09,  ..., 2.4519e-12, 6.0054e-09,\n",
      "         3.2082e-12],\n",
      "        [5.4693e-08, 4.2021e-08, 3.4865e-08,  ..., 2.6336e-09, 4.8632e-08,\n",
      "         2.2781e-09],\n",
      "        ...,\n",
      "        [2.2519e-08, 9.1945e-09, 2.6939e-08,  ..., 9.6441e-13, 3.0745e-08,\n",
      "         1.1025e-12],\n",
      "        [8.5065e-08, 5.7068e-08, 6.0028e-08,  ..., 2.9789e-09, 1.3468e-07,\n",
      "         2.6312e-09],\n",
      "        [6.5222e-07, 3.1881e-07, 3.5244e-07,  ..., 4.7401e-10, 4.8606e-07,\n",
      "         6.7064e-10]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n",
      "====> Generated text after epoch 10: tensor([[8.3627e-12, 2.4191e-11, 3.9996e-13,  ..., 3.0314e-10, 4.3225e-12,\n",
      "         9.1241e-11],\n",
      "        [1.7307e-10, 3.0319e-10, 7.9093e-12,  ..., 2.7587e-09, 7.0227e-11,\n",
      "         1.8484e-09],\n",
      "        [1.3907e-08, 3.0825e-08, 1.6846e-09,  ..., 1.1738e-07, 1.1287e-08,\n",
      "         8.2214e-08],\n",
      "        ...,\n",
      "        [2.2519e-09, 2.5694e-09, 4.5372e-10,  ..., 1.9606e-08, 2.2638e-09,\n",
      "         1.1736e-08],\n",
      "        [6.6837e-11, 7.1597e-11, 2.1307e-12,  ..., 1.6420e-09, 2.6576e-11,\n",
      "         6.0230e-10],\n",
      "        [6.2822e-09, 5.6450e-09, 5.3457e-10,  ..., 1.1246e-07, 4.6439e-09,\n",
      "         1.0343e-07]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def generate_text(epoch):\n",
    "    model.eval()\n",
    "    sample = torch.randn(64, 20).to(device)  # Move the tensor to the GPU\n",
    "    sample = model.decode(sample)\n",
    "    print('====> Generated text after epoch {}: {}'.format(epoch, sample))\n",
    "\n",
    "for epoch in range(1, 10 + 1):\n",
    "    generate_text(epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dac84e-47db-4b86-80e4-85a417402e29",
   "metadata": {},
   "source": [
    "### Project and sample sentences from the latent space\n",
    "Now we build an encoder model model that takes a sentence and projects it on the latent space and a decoder model that goes from the latent space back to the text representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67409644-0197-45b0-bba7-5b1add14b13d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# build a model to project inputs on the latent space\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 400)\n",
    "        self.fc21 = nn.Linear(400, 20)\n",
    "        self.fc22 = nn.Linear(400, 20)\n",
    "    def forward(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "# build a generator that can sample from the learned distribution\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 768)\n",
    "    def forward(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "encoder = Encoder().to(device)\n",
    "decoder = Decoder().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02096c2d-9537-4cda-a7c1-8c17da55c44d",
   "metadata": {},
   "source": [
    "### Test on validation sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43a18390-c881-4188-a6f3-13b589590710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T08:09:52.036309+00:00",
     "start_time": "2023-07-01T08:09:51.495205+00:00"
    },
    "noteable": {
     "output_collection_id": "20c15316-95f5-49a0-ae60-65dbabf21f5b"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (768x1535 and 768x400)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#test on a validation sentence\u001b[39;00m\n\u001b[0;32m      5\u001b[0m sent_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 6\u001b[0m sent_encoded \u001b[38;5;241m=\u001b[39m encoder(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion1\u001b[39m\u001b[38;5;124m'\u001b[39m][sent_idx])\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m      7\u001b[0m x_test_reconstructed \u001b[38;5;241m=\u001b[39m decoder(sent_encoded)\n\u001b[0;32m      8\u001b[0m reconstructed_indexes \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(x_test_reconstructed, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[18], line 9\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m----> 9\u001b[0m     h1 \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(x))\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc21(h1), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc22(h1)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (768x1535 and 768x400)"
     ]
    }
   ],
   "source": [
    "index2word = {v: k for k, v in tokenizer.get_vocab().items()}\n",
    "index2word[0] = 'pad'\n",
    "\n",
    "#test on a validation sentence\n",
    "sent_idx = 100\n",
    "sent_encoded = encoder(torch.from_numpy(data['question1'][sent_idx]).to(device))\n",
    "x_test_reconstructed = decoder(sent_encoded)\n",
    "reconstructed_indexes = torch.argmax(x_test_reconstructed, dim=1).cpu().numpy()\n",
    "word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "print(' '.join(word_list))\n",
    "original_sent = list(np.vectorize(index2word.get)(data['question1'][sent_idx]))\n",
    "print(' '.join(original_sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd188ea9-6f6f-4870-84ca-66e8ed1b56f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentence processing and interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50224de7-dbdb-4ac2-9b6f-c22ddbb531bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse a sentence\n",
    "def sent_parse(sentence, mat_shape):\n",
    "    sequence = tokenizer.encode(sentence)\n",
    "    padded_sent = pad_sequence(sequence)\n",
    "    return padded_sent\n",
    "\n",
    "# input: encoded sentence vector\n",
    "# output: encoded sentence vector in dataset with highest cosine similarity\n",
    "def find_similar_encoding(sent_vect):\n",
    "    all_cosine = []\n",
    "    for sent in data['question1']:\n",
    "        result = 1 - spatial.distance.cosine(sent_vect, sent)\n",
    "        all_cosine.append(result)\n",
    "    data_array = np.array(all_cosine)\n",
    "    maximum = data_array.argsort()[-3:][::-1][1]\n",
    "    new_vec = data['question1'][maximum]\n",
    "    return new_vec\n",
    "\n",
    "# input: two points, integer n\n",
    "# output: n equidistant points on the line between the input points (inclusive)\n",
    "def shortest_homology(point_one, point_two, num):\n",
    "    dist_vec = point_two - point_one\n",
    "    sample = np.linspace(0, 1, num, endpoint = True)\n",
    "    hom_sample = []\n",
    "    for s in sample:\n",
    "        hom_sample.append(point_one + s * dist_vec)\n",
    "    return hom_sample\n",
    "\n",
    "# input: original dimension sentence vector\n",
    "# output: sentence text\n",
    "def print_latent_sentence(sent_vect):\n",
    "    sent_vect = torch.tensor(sent_vect).to(device)\n",
    "    sent_reconstructed = decoder(sent_vect)\n",
    "    reconstructed_indexes = torch.argmax(sent_reconstructed, dim=1).cpu().numpy()\n",
    "    word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "    print(' '.join(word_list))\n",
    "\n",
    "def new_sents_interp(sent1, sent2, n):\n",
    "    tok_sent1 = sent_parse(sent1, [MAX_SEQUENCE_LENGTH + 2])\n",
    "    tok_sent2 = sent_parse(sent2, [MAX_SEQUENCE_LENGTH + 2])\n",
    "    enc_sent1 = encoder(torch.tensor(tok_sent1).to(device))\n",
    "    enc_sent2 = encoder(torch.tensor(tok_sent2).to(device))\n",
    "    test_hom = shortest_homology(enc_sent1.detach().cpu().numpy(), enc_sent2.detach().cpu().numpy(), n)\n",
    "    for point in test_hom:\n",
    "        print_latent_sentence(point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07026ef-806a-4fab-8029-26158fc325c0",
   "metadata": {},
   "source": [
    "### Example\n",
    "Now we can try to parse two sentences and interpolate between them generating new sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bf6b6e-8280-41d7-80dc-f269123fd65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1='where can i find a bad restaurant'\n",
    "mysent = sent_parse(sentence1, [MAX_SEQUENCE_LENGTH + 2])\n",
    "mysent_encoded = encoder(torch.tensor(mysent).to(device))\n",
    "print_latent_sentence(mysent_encoded.detach().cpu().numpy())\n",
    "print_latent_sentence(find_similar_encoding(mysent_encoded.detach().cpu().numpy()))\n",
    "\n",
    "sentence2='where can i find an extremely good restaurant'\n",
    "mysent2 = sent_parse(sentence2, [MAX_SEQUENCE_LENGTH + 2])\n",
    "mysent_encoded2 = encoder(torch.tensor(mysent2).to(device))\n",
    "print_latent_sentence(mysent_encoded2.detach().cpu().numpy())\n",
    "print_latent_sentence(find_similar_encoding(mysent_encoded2.detach().cpu().numpy()))\n",
    "print('-----------------')\n",
    "\n",
    "new_sents_interp(sentence1, sentence2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62c9bd3-f387-436f-b399-0241f2413cb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T08:10:44.652129+00:00",
     "start_time": "2023-07-01T08:10:44.488358+00:00"
    },
    "noteable": {
     "cell_type": "code",
     "output_collection_id": "04544167-be72-401c-a5fe-7e347c101fac"
    }
   },
   "outputs": [],
   "source": [
    "# function to parse a sentence\n",
    "def sent_parse(sentence, tokenizer, device):\n",
    "    sequence = tokenizer.encode_plus(sentence, return_tensors='pt')\n",
    "    return sequence['input_ids'].to(device)\n",
    "\n",
    "# input: encoded sentence vector\n",
    "# output: encoded sentence vector in dataset with highest cosine similarity\n",
    "def find_similar_encoding(sent_vect, encoded_data):\n",
    "    all_cosine = []\n",
    "    for sent in encoded_data:\n",
    "        result = 1 - spatial.distance.cosine(sent_vect.cpu().numpy(), sent.cpu().numpy())\n",
    "        all_cosine.append(result)\n",
    "    data_array = np.array(all_cosine)\n",
    "    maximum = data_array.argsort()[-3:][::-1][1]\n",
    "    new_vec = encoded_data[maximum]\n",
    "    return new_vec\n",
    "\n",
    "# input: two points, integer n\n",
    "# output: n equidistant points on the line between the input points (inclusive)\n",
    "def shortest_homology(point_one, point_two, num):\n",
    "    dist_vec = point_two - point_one\n",
    "    sample = np.linspace(0, 1, num, endpoint = True)\n",
    "    hom_sample = []\n",
    "    for s in sample:\n",
    "        hom_sample.append(point_one + s * dist_vec)\n",
    "    return hom_sample\n",
    "\n",
    "# input: original dimension sentence vector\n",
    "# output: sentence text\n",
    "def print_latent_sentence(sent_vect, decoder, index2word):\n",
    "    sent_vect = sent_vect.unsqueeze(0)\n",
    "    sent_reconstructed = decoder(sent_vect)\n",
    "    reconstructed_indexes = torch.argmax(sent_reconstructed, dim=2).squeeze().cpu().numpy()\n",
    "    word_list = list(np.vectorize(index2word.get)(reconstructed_indexes))\n",
    "    print(' '.join(word_list))\n",
    "\n",
    "def new_sents_interp(sent1, sent2, n, tokenizer, device, encoder, decoder, index2word):\n",
    "    tok_sent1 = sent_parse(sent1, tokenizer, device)\n",
    "    tok_sent2 = sent_parse(sent2, tokenizer, device)\n",
    "    enc_sent1 = encoder(tok_sent1)\n",
    "    enc_sent2 = encoder(tok_sent2)\n",
    "    test_hom = shortest_homology(enc_sent1, enc_sent2, n)\n",
    "    for point in test_hom:\n",
    "        print_latent_sentence(point, decoder, index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944f9619-5d6a-4318-a786-254d49ac05c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-01T08:11:28.138813+00:00",
     "start_time": "2023-07-01T08:11:27.959011+00:00"
    },
    "noteable": {
     "cell_type": "code",
     "output_collection_id": "3d68e9ae-74ec-4362-b010-c83a3356d776"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sentence1='where can i find a bad restaurant'\n",
    "sentence2='where can i find an extremely good restaurant'\n",
    "new_sents_interp(sentence1, sentence2, 5, tokenizer, device, encoder, decoder, index2word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "noteable": {
   "last_delta_id": "4a3fbf04-ef34-460b-b616-055e9285c30e",
   "last_transaction_id": "891716eb-2a0e-40d6-a258-8d5b45143b95"
  },
  "noteable-chatgpt": {
   "create_notebook": {
    "openai_conversation_id": "b2c6ef96-6967-5cef-872b-98d4c190f96e",
    "openai_ephemeral_user_id": "4eca9769-3ab9-5591-bb64-729453b68e61",
    "openai_subdivision1_iso_code": "AU-NSW"
   }
  },
  "nteract": {
   "version": "noteable@2.9.0"
  },
  "selected_hardware_size": "small"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
